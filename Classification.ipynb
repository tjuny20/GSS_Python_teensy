{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "15fd4df13beb9f5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "import torch\n",
    "from torch.linalg import inv, eig, pinv\n",
    "from matplotlib import pyplot as plt\n",
    "from tools import whiten, adap_whitening, adap_whitening_2\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "import pickle\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from tools import load, split, estimate_derivative, plot_two_intervals\n",
    "from cycler import cycler\n",
    "from matplotlib.colors import ListedColormap"
   ],
   "id": "5ed262a9e56907ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rng = np.random.default_rng(42)  # for reproducibility\n",
    "cm = ListedColormap(plt.rcParams['axes.prop_cycle'].by_key()['color'])"
   ],
   "id": "8b7814760cee48b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_blocks(labels, max_len=20, ignore=0):\n",
    "    \"\"\"\n",
    "    Split a 1D array of integer labels into contiguous blocks.\n",
    "    - Blocks with label == `ignore` (default 0) are skipped.\n",
    "    - Long runs are split into chunks of at most `max_len`.\n",
    "    Returns: list of (start_idx, end_idx, label) with end_idx exclusive.\n",
    "    \"\"\"\n",
    "    labels = np.asarray(labels)\n",
    "    n = len(labels)\n",
    "    if n == 0:\n",
    "        return []\n",
    "\n",
    "    blocks = []\n",
    "    start = 0\n",
    "    prev = labels[0]\n",
    "\n",
    "    # walk + flush on change (and once at the end)\n",
    "    for i in range(1, n + 1):\n",
    "        cur = labels[i] if i < n else None\n",
    "        if cur != prev:\n",
    "            if prev != ignore:\n",
    "                run_start, run_end, lab = start, i, int(prev)\n",
    "                # chunk the run to respect max_len\n",
    "                s = run_start\n",
    "                while s < run_end:\n",
    "                    e = min(s + max_len, run_end)\n",
    "                    blocks.append((s, e, lab))\n",
    "                    s = e\n",
    "            start = i\n",
    "            prev = cur\n",
    "\n",
    "    return blocks"
   ],
   "id": "64173cc84896b5d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- load ---\n",
    "with open(\"data/params_texel.pkl\", \"rb\") as f:\n",
    "    d = pickle.load(f)\n",
    "\n",
    "k  = np.asarray(d[\"params\"][\"k\"])\n",
    "p  = np.asarray(d[\"params\"][\"p\"])\n",
    "ta = np.asarray(d[\"results\"][\"test_acc\"], dtype=float)\n",
    "\n",
    "# --- group by (k, p) and compute means across folds (no pandas) ---\n",
    "# sort by (k, p)\n",
    "idx = np.lexsort((p, k))       # primary k, then p\n",
    "ks, ps, tas = k[idx], p[idx], ta[idx]\n",
    "\n",
    "# find group starts where (k, p) changes\n",
    "chg = (ks[1:] != ks[:-1]) | (ps[1:] != ps[:-1])\n",
    "starts = np.r_[0, np.flatnonzero(chg) + 1]\n",
    "\n",
    "# sums and counts per group → means\n",
    "sums = np.add.reduceat(tas, starts)\n",
    "counts = np.diff(np.r_[starts, tas.size])\n",
    "means = sums / counts\n",
    "\n",
    "gk = ks[starts]   # k per group\n",
    "gp = ps[starts]   # p per group\n",
    "\n",
    "# --- put into a 2D grid (rows=k, cols=p) ---\n",
    "ku = np.unique(k)\n",
    "pu = np.unique(p)\n",
    "grid = np.full((ku.size, pu.size), np.nan)\n",
    "\n",
    "ki = np.searchsorted(ku, gk)\n",
    "pi = np.searchsorted(pu, gp)\n",
    "grid[ki, pi] = means\n",
    "\n",
    "# --- plot ---\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "im = ax.imshow(grid, aspect=\"auto\")  # default colormap\n",
    "ax.set_xticks(np.arange(pu.size)); ax.set_xticklabels(pu)\n",
    "ax.set_yticks(np.arange(ku.size)); ax.set_yticklabels(ku)\n",
    "ax.set_xlabel(\"p\")\n",
    "ax.set_ylabel(\"k\")\n",
    "ax.set_title(\"Mean test_acc across folds\")\n",
    "\n",
    "# annotate cells\n",
    "for i in range(grid.shape[0]):\n",
    "    for j in range(grid.shape[1]):\n",
    "        if np.isfinite(grid[i, j]):\n",
    "            ax.text(j, i, f\"{grid[i, j]:.3f}\", ha=\"center\", va=\"center\")\n",
    "\n",
    "fig.colorbar(im, ax=ax, label=\"mean test_acc\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "5d979b9a48c7aae4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k       = np.asarray(d[\"params\"][\"k\"])\n",
    "p       = np.asarray(d[\"params\"][\"p\"])\n",
    "n_fold  = np.asarray(d[\"params\"][\"n_fold\"])\n",
    "testacc = np.asarray(d[\"results\"][\"test_acc\"], dtype=float)\n",
    "\n",
    "# --- group by (k, p) and compute mean across folds ---\n",
    "idx = np.lexsort((p, k))           # sort by k, then p\n",
    "ks, ps, tas = k[idx], p[idx], testacc[idx]\n",
    "\n",
    "chg = (ks[1:] != ks[:-1]) | (ps[1:] != ps[:-1])\n",
    "starts = np.r_[0, np.flatnonzero(chg) + 1]\n",
    "\n",
    "sums   = np.add.reduceat(tas, starts)\n",
    "counts = np.diff(np.r_[starts, tas.size])\n",
    "means  = sums / counts\n",
    "\n",
    "gk = ks[starts]\n",
    "gp = ps[starts]\n",
    "\n",
    "# --- pick best group by highest mean ---\n",
    "best_group = int(np.nanargmax(means))\n",
    "best_k = gk[best_group]\n",
    "best_p = gp[best_group]\n",
    "\n",
    "# all folds at those params\n",
    "mask = (k == best_k) & (p == best_p)\n",
    "best_vals = testacc[mask]\n",
    "best_folds = n_fold[mask]\n",
    "\n",
    "# best single-fold at those params\n",
    "best_single_idx = int(np.nanargmax(best_vals))\n",
    "best_n_fold = best_folds[best_single_idx]\n",
    "\n",
    "# --- print in requested style (adapted: p instead of N_pot, no t_delay available) ---\n",
    "print(\n",
    "    f\"Best params → k={best_k}, p={best_p}\\n\"\n",
    "    f\"Highest mean test accuracy: {np.nanmean(best_vals):.4f} ± {np.nanstd(best_vals):.4f} (n={best_vals.size})\\n\"\n",
    "    f\"Highest single-fold test accuracy at those params: {np.nanmax(best_vals):.4f}, n_fold={best_n_fold}\"\n",
    ")"
   ],
   "id": "b03a5deb8901b192",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- load ---\n",
    "with open(\"data/gridsearch_pseudoderivative.pkl\", \"rb\") as f:\n",
    "    d = pickle.load(f)\n",
    "\n",
    "k  = np.asarray(d[\"params\"][\"k\"])\n",
    "p  = np.asarray(d[\"params\"][\"p\"])\n",
    "ta = np.asarray(d[\"results\"][\"test_acc\"], dtype=float)\n",
    "\n",
    "# --- group by (k, p) and compute means across folds (no pandas) ---\n",
    "# sort by (k, p)\n",
    "idx = np.lexsort((p, k))       # primary k, then p\n",
    "ks, ps, tas = k[idx], p[idx], ta[idx]\n",
    "\n",
    "# find group starts where (k, p) changes\n",
    "chg = (ks[1:] != ks[:-1]) | (ps[1:] != ps[:-1])\n",
    "starts = np.r_[0, np.flatnonzero(chg) + 1]\n",
    "\n",
    "# sums and counts per group → means\n",
    "sums = np.add.reduceat(tas, starts)\n",
    "counts = np.diff(np.r_[starts, tas.size])\n",
    "means = sums / counts\n",
    "\n",
    "gk = ks[starts]   # k per group\n",
    "gp = ps[starts]   # p per group\n",
    "\n",
    "# --- put into a 2D grid (rows=k, cols=p) ---\n",
    "ku = np.unique(k)\n",
    "pu = np.unique(p)\n",
    "grid = np.full((ku.size, pu.size), np.nan)\n",
    "\n",
    "ki = np.searchsorted(ku, gk)\n",
    "pi = np.searchsorted(pu, gp)\n",
    "grid[ki, pi] = means\n",
    "\n",
    "# --- plot ---\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "im = ax.imshow(grid, aspect=\"auto\")  # default colormap\n",
    "ax.set_xticks(np.arange(pu.size)); ax.set_xticklabels(pu)\n",
    "ax.set_yticks(np.arange(ku.size)); ax.set_yticklabels(ku)\n",
    "ax.set_xlabel(\"p\")\n",
    "ax.set_ylabel(\"k\")\n",
    "ax.set_title(\"Mean test_acc across folds\")\n",
    "\n",
    "# annotate cells\n",
    "for i in range(grid.shape[0]):\n",
    "    for j in range(grid.shape[1]):\n",
    "        if np.isfinite(grid[i, j]):\n",
    "            ax.text(j, i, f\"{grid[i, j]:.3f}\", ha=\"center\", va=\"center\")\n",
    "\n",
    "fig.colorbar(im, ax=ax, label=\"mean test_acc\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "33e01b2ad573633f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k       = np.asarray(d[\"params\"][\"k\"])\n",
    "p       = np.asarray(d[\"params\"][\"p\"])\n",
    "n_fold  = np.asarray(d[\"params\"][\"n_fold\"])\n",
    "testacc = np.asarray(d[\"results\"][\"test_acc\"], dtype=float)\n",
    "\n",
    "# --- group by (k, p) and compute mean across folds ---\n",
    "idx = np.lexsort((p, k))           # sort by k, then p\n",
    "ks, ps, tas = k[idx], p[idx], testacc[idx]\n",
    "\n",
    "chg = (ks[1:] != ks[:-1]) | (ps[1:] != ps[:-1])\n",
    "starts = np.r_[0, np.flatnonzero(chg) + 1]\n",
    "\n",
    "sums   = np.add.reduceat(tas, starts)\n",
    "counts = np.diff(np.r_[starts, tas.size])\n",
    "means  = sums / counts\n",
    "\n",
    "gk = ks[starts]\n",
    "gp = ps[starts]\n",
    "\n",
    "# --- pick best group by highest mean ---\n",
    "best_group = int(np.nanargmax(means))\n",
    "best_k = gk[best_group]\n",
    "best_p = gp[best_group]\n",
    "\n",
    "# all folds at those params\n",
    "mask = (k == best_k) & (p == best_p)\n",
    "best_vals = testacc[mask]\n",
    "best_folds = n_fold[mask]\n",
    "\n",
    "# best single-fold at those params\n",
    "best_single_idx = int(np.nanargmax(best_vals))\n",
    "best_n_fold = best_folds[best_single_idx]\n",
    "\n",
    "# --- print in requested style (adapted: p instead of N_pot, no t_delay available) ---\n",
    "print(\n",
    "    f\"Best params → k={best_k}, p={best_p}\\n\"\n",
    "    f\"Highest mean test accuracy: {np.nanmean(best_vals):.4f} ± {np.nanstd(best_vals):.4f} (n={best_vals.size})\\n\"\n",
    "    f\"Highest single-fold test accuracy at those params: {np.nanmax(best_vals):.4f}, n_fold={best_n_fold}\"\n",
    ")"
   ],
   "id": "fa6f711ff3c48ea7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_hd = 10000\n",
    "n_out = 3\n",
    "k = 200\n",
    "p = 0.005\n",
    "p_w_hd = 0.05\n",
    "n_train = 450\n",
    "\n",
    "normalized = False\n",
    "whitened = True\n",
    "\n",
    "filename = '1_600_20'\n",
    "\n",
    "sensor_data, sequence, times_sec, sequence_sec = load(filename, reduced=True)\n",
    "d_sensor_data = np.apply_along_axis(estimate_derivative, axis=0, arr=sensor_data)\n",
    "sensor_data = np.hstack((sensor_data, d_sensor_data))\n",
    "\n",
    "# baseline = np.mean(sensor_data[:300], axis=0)  # Add baseline substraction\n",
    "# sensor_data = (sensor_data - baseline)\n",
    "\n",
    "if normalized:\n",
    "    sensor_data = (sensor_data - np.mean(sensor_data, axis=0))/ np.std(sensor_data, axis=0)\n",
    "if whitened:\n",
    "    sensor_data = whiten(sensor_data)\n",
    "\n",
    "x_dense = sensor_data\n",
    "n_dense = x_dense.shape[1]\n",
    "\n",
    "labels = np.zeros_like(times_sec)\n",
    "for i, t in enumerate(sequence_sec[:n_train]):\n",
    "    try:\n",
    "        flag = (times_sec > sequence_sec[i]) & (times_sec < sequence_sec[i+1])\n",
    "    except IndexError:\n",
    "        flag = (times_sec > sequence_sec[i])\n",
    "    labels[flag] = int(sequence[i][1])\n",
    "\n",
    "idx_last_flag = np.where(labels != 0)[0][-1]\n",
    "\n",
    "W_hd = np.random.binomial(n=1, p=p_w_hd, size=(n_hd, n_dense))  #Test random sparse weights\n",
    "x_hd = x_dense @ W_hd.T\n",
    "ranks = np.argsort(np.argsort(-x_hd, axis=1), axis=1)\n",
    "z_hd = np.where(ranks < k, 1., 0.)\n",
    "W_out = np.zeros((n_out, n_hd))\n",
    "W = np.zeros((n_out, n_hd))\n",
    "\n",
    "z_out_train = np.zeros((z_hd.shape[0],  n_out))\n",
    "for i, row in enumerate(z_hd[:idx_last_flag]):\n",
    "    if labels[i] != 0:\n",
    "        active_idx = np.flatnonzero(row)\n",
    "        to_flip = active_idx[rng.random(active_idx.size) < p]     # Bernoulli(p) per active index# indices where z_hd==1\n",
    "        W_out[int(labels[i])-1, to_flip] = 1./k\n",
    "\n",
    "\n",
    "    out = row @ W_out.T\n",
    "    z_out_train[i] = out\n",
    "\n",
    "z_out_acc = np.zeros((z_hd.shape[0],  n_out))\n",
    "for i, row in enumerate(z_hd):\n",
    "    out = row @ W_out.T\n",
    "    z_out_acc[i] = out\n",
    "\n",
    "ranks_out = np.argsort(np.argsort(-z_out_acc, axis=1), axis=1)\n",
    "z_wta = np.where(ranks_out < 1, 1., 0.)\n",
    "\n",
    "z_pred = np.zeros_like(sequence_sec)\n",
    "z_true = np.zeros_like(sequence_sec)\n",
    "for i, t in enumerate(sequence_sec):\n",
    "    try:\n",
    "        flag = (times_sec > sequence_sec[i]) & (times_sec < sequence_sec[i+1])\n",
    "    except IndexError:\n",
    "        flag = (times_sec > sequence_sec[i])\n",
    "    z_pred[i] = np.argsort(np.sum(z_out_acc[flag], axis=0))[-1] + 1\n",
    "    z_true[i] = sequence[i][1]\n",
    "\n",
    "train_acc = sklearn.metrics.accuracy_score(z_true[:n_train], z_pred[:n_train])\n",
    "test_acc = sklearn.metrics.accuracy_score(z_true[n_train:], z_pred[n_train:])\n",
    "\n",
    "print(f'k: {k}, p: {p}')\n",
    "print(f'Train accuracy: {train_acc:.4f}, Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "z_out = np.empty((z_hd.shape[0],  n_out))\n",
    "z_out[:idx_last_flag] = z_out_train[:idx_last_flag]\n",
    "z_out[idx_last_flag:] = z_out_acc[idx_last_flag:]"
   ],
   "id": "e14991f85f6cec28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ===== Combined 2x2 figure with nested GridSpec =====\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# --- your existing config for the TOP row plot (unchanged) ---\n",
    "top_intervals_idx = [(0, 6), (212, 218)]   # left & middle (sequence-index windows)\n",
    "j0, j1 = 235, 241                           # right \"Test\" (sequence-index)\n",
    "max_len = 20\n",
    "sigma = 2.\n",
    "savepath = 'figs/hd_out'  # will still save individual top-row figure products if you keep those lines\n",
    "connector_color   = 'black'\n",
    "connector_lw      = 1.\n",
    "connector_ls      = ':'      # dotted\n",
    "slash_color       = 'black'\n",
    "slash_lw          = 1.\n",
    "slash_len_fig     = 0.015\n",
    "slash_angle_deg   = 60\n",
    "slash_inset       = 0.003\n",
    "\n",
    "\n",
    "# ----- per-sample block labels over full recording (unchanged) -----\n",
    "colour = np.zeros_like(times_sec, dtype=int)\n",
    "for i in range(len(sequence_sec)):\n",
    "    t_start = sequence_sec[i]\n",
    "    t_end = sequence_sec[i + 1] if i + 1 < len(sequence_sec) else np.inf\n",
    "    mask = (times_sec >= t_start) & (times_sec < t_end)\n",
    "    colour[mask] = int(sequence[i][1])\n",
    "\n",
    "# ----- helpers (unchanged) -----\n",
    "def seq_idx_window_to_sample_idx(a_idx, b_idx):\n",
    "    a_idx = int(np.clip(a_idx, 0, len(sequence_sec) - 1))\n",
    "    b_idx = int(np.clip(b_idx, 0, len(sequence_sec) - 1))\n",
    "    t0_sec = sequence_sec[a_idx]\n",
    "    t1_sec = sequence_sec[b_idx]\n",
    "    t0 = int(np.abs(times_sec - t0_sec).argmin())\n",
    "    t1 = int(np.abs(times_sec - t1_sec).argmin())\n",
    "    if t1 <= t0:\n",
    "        t1 = min(t0 + 1, len(times_sec))\n",
    "    return t0, t1\n",
    "\n",
    "def find_blocks(labels, max_len=20, ignore=0):\n",
    "    labels = np.asarray(labels)\n",
    "    n = len(labels)\n",
    "    if n == 0: return []\n",
    "    blocks, start, prev = [], 0, labels[0]\n",
    "    for i in range(1, n + 1):\n",
    "        cur = labels[i] if i < n else None\n",
    "        if cur != prev:\n",
    "            if prev != ignore:\n",
    "                run_start, run_end, lab = start, i, int(prev)\n",
    "                s = run_start\n",
    "                while s < run_end:\n",
    "                    e = min(s + max_len, run_end)\n",
    "                    blocks.append((s, e, lab))  # [s, e) end-exclusive\n",
    "                    s = e\n",
    "            start, prev = i, cur\n",
    "    return blocks\n",
    "\n",
    "def block_edges_from_indices(x, s, e):\n",
    "    if s <= 0:\n",
    "        L = x[0]\n",
    "    else:\n",
    "        L = 0.5 * (x[s-1] + x[s])\n",
    "    if e >= len(x):\n",
    "        R = x[-1]\n",
    "    else:\n",
    "        R = 0.5 * (x[e-1] + x[e])\n",
    "    return L, R\n",
    "\n",
    "# --- Build outer 2x2 figure (unchanged) ---\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "gs = GridSpec(2, 2, figure=fig, height_ratios=[1.0, 1.5], width_ratios=[1.0, 1.0], hspace=0.7, wspace=0.4)\n",
    "\n",
    "# Top row (unchanged)\n",
    "gs_top = gs[0, :].subgridspec(1, 3, wspace=0.25)\n",
    "ax_l = fig.add_subplot(gs_top[0, 0])\n",
    "ax_m = fig.add_subplot(gs_top[0, 1])\n",
    "ax_r = fig.add_subplot(gs_top[0, 2])\n",
    "\n",
    "# Bottom-left (SVM vs Maya)\n",
    "ax_bl = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "# Bottom-right\n",
    "ax_br = fig.add_subplot(gs[1, 1])\n",
    "# ax_br.axis('off')\n",
    "\n",
    "# Panel labels 'a', 'b', 'c'\n",
    "ax_l.text(-0.18, 1.2, 'a)', transform=ax_l.transAxes,\n",
    "            fontsize=12, ha='right', va='bottom')\n",
    "ax_bl.text(-0.12, 1.08, 'b)', transform=ax_bl.transAxes,\n",
    "            fontsize=12, ha='right', va='bottom')\n",
    "ax_br.text(-0.07, 1.08, 'c)', transform=ax_br.transAxes,\n",
    "            fontsize=12, ha='right', va='bottom')\n",
    "\n",
    "# ----- windows (sample indices) for TOP row -----\n",
    "t0_a, t1_a       = seq_idx_window_to_sample_idx(*top_intervals_idx[0])  # left\n",
    "t0_b, t1_b       = seq_idx_window_to_sample_idx(*top_intervals_idx[1])  # middle\n",
    "t0_test, t1_test = seq_idx_window_to_sample_idx(j0, j1)                 # right\n",
    "\n",
    "# GLOBAL origin: first time from LEFT window\n",
    "x0_ref = times_sec[t0_a]\n",
    "\n",
    "def plot_interval_time_x(ah, t0, t1, title=None, pos=None, hide_y=False):\n",
    "    # time axis shifted by the SAME origin (x0_ref)\n",
    "    x_raw = times_sec[t0:t1]\n",
    "    x = x_raw - x0_ref\n",
    "\n",
    "    labels_local = colour[t0:t1]\n",
    "    blocks = find_blocks(labels_local, max_len=max_len)\n",
    "\n",
    "    # traces vs time\n",
    "    for i in range(z_out.shape[1]):\n",
    "        smoothed = gaussian_filter1d(z_out[t0:t1, i], sigma=sigma)\n",
    "        ah.plot(x, smoothed, label=f'Neuron {i+1}', color=cm(i % cm.N), linewidth=1.2, alpha=0.85)\n",
    "\n",
    "    # shaded blocks (midpoint edges => no gaps)\n",
    "    for s, e, lab in blocks:\n",
    "        if lab == 0:\n",
    "            continue\n",
    "        L, R = block_edges_from_indices(x, s, e)\n",
    "        if R > L:\n",
    "            ah.axvspan(L, R, facecolor=cm((lab-1) % cm.N), alpha=0.15, linewidth=0)\n",
    "\n",
    "    # axes styling\n",
    "    ah.set_xlim(x[0], x[-1])\n",
    "    ah.set_ylim(0., 1.)\n",
    "\n",
    "    if not hide_y:\n",
    "        ah.set_yticks([0, 1])\n",
    "    else:\n",
    "        ah.set_yticks([])\n",
    "        ah.set_ylabel(\"\")\n",
    "        ah.spines['left'].set_visible(False)\n",
    "\n",
    "    if title:\n",
    "        if pos==\"left\":\n",
    "            ah.text(0.01, 1.15, title, transform=ah.transAxes,\n",
    "                    va=\"center\", ha=\"left\", fontsize=12)\n",
    "        elif pos==\"right\":\n",
    "            ah.text(0.99, 1.15, title, transform=ah.transAxes,\n",
    "                    va=\"center\", ha=\"right\", fontsize=12)\n",
    "\n",
    "# ----- TOP row: plot panels (single row) -----\n",
    "plot_interval_time_x(ax_l, t0_a,   t1_a,   title=None,                  hide_y=False)  # left\n",
    "plot_interval_time_x(ax_m, t0_b,   t1_b,   title=\"Train\", pos='right',  hide_y=True)   # middle (hide y)\n",
    "plot_interval_time_x(ax_r, t0_test,t1_test,title=\"Test\",  pos='left',   hide_y=True)   # right\n",
    "\n",
    "# ----- Gas labels (TOP row) -----\n",
    "gas_names = {1: \"CO\", 2: \"Ethylene\", 3: \"Methane\"}\n",
    "def _label_for(lab): return gas_names.get(lab, f\"Gas {lab}\")\n",
    "\n",
    "def add_gas_labels(ah, t0, t1, offset_frac=0.05, angle_deg=45):\n",
    "    x_raw = times_sec[t0:t1]\n",
    "    x = x_raw - x0_ref\n",
    "    labels_local = colour[t0:t1]\n",
    "    blocks = find_blocks(labels_local, max_len=max_len)\n",
    "    y0, y1 = ah.get_ylim()\n",
    "    y_off = 0.02 * (y1 - y0)\n",
    "    prev_lab = None\n",
    "    for s, e, lab in blocks:\n",
    "        if lab == 0 or lab == prev_lab:\n",
    "            prev_lab = lab\n",
    "            continue\n",
    "        prev_lab = lab\n",
    "        L, R = block_edges_from_indices(x, s, e)\n",
    "        if R <= L: continue\n",
    "        x_mid = 0.5 * (L + R)\n",
    "        dx = offset_frac * (R - L)\n",
    "        x_lbl = x_mid + dx\n",
    "        ah.text(\n",
    "            x_lbl, y1 + y_off, _label_for(int(lab)),\n",
    "            color=cm((int(lab) - 1) % cm.N),\n",
    "            ha=\"left\", va=\"bottom\", fontsize=10,\n",
    "            rotation=angle_deg, rotation_mode=\"anchor\",\n",
    "            transform=ah.transData, clip_on=False\n",
    "        )\n",
    "\n",
    "t0_labels, t1_labels = seq_idx_window_to_sample_idx(0, 3)\n",
    "add_gas_labels(ax_l, t0_labels, t1_labels)\n",
    "\n",
    "# labels\n",
    "ax_l.set_ylabel(\"Output neuron\\nactivity (a.u.)\")\n",
    "ax_m.set_xlabel(\"Time (s)\")\n",
    "\n",
    "# legend above the right subplot (TOP row)\n",
    "handles, labels_ = ax_l.get_legend_handles_labels()\n",
    "ax_r.legend(handles, labels_, frameon=False, loc=\"lower center\",\n",
    "            bbox_to_anchor=(0.9, 1.05), ncol=1)\n",
    "\n",
    "# ----- dotted connectors + slashes (TOP row) -----\n",
    "def bottom_anchor_in_fig(ax, x_in_axes):\n",
    "    pt_disp = ax.transAxes.transform((x_in_axes, 0.0))\n",
    "    return fig.transFigure.inverted().transform(pt_disp)\n",
    "\n",
    "# exact anchors at spine ends\n",
    "pL_right = bottom_anchor_in_fig(ax_l, 1.0)\n",
    "pM_left  = bottom_anchor_in_fig(ax_m, 0.0)\n",
    "pM_right = bottom_anchor_in_fig(ax_m, 1.0)\n",
    "pR_left  = bottom_anchor_in_fig(ax_r, 0.0)\n",
    "pR_right = bottom_anchor_in_fig(ax_r, 1.0)\n",
    "\n",
    "theta  = np.deg2rad(slash_angle_deg)\n",
    "dx_fig = slash_len_fig * np.cos(theta)\n",
    "dy_fig = slash_len_fig * np.sin(theta)\n",
    "stub   = 0.04\n",
    "\n",
    "def draw_centered_slash(anchor_xy):\n",
    "    xA, yA = anchor_xy\n",
    "    fig.add_artist(Line2D([xA - dx_fig/2, xA + dx_fig/2],\n",
    "                          [yA - dy_fig/2, yA + dy_fig/2],\n",
    "                          transform=fig.transFigure, lw=slash_lw,\n",
    "                          color=slash_color, clip_on=False))\n",
    "\n",
    "def draw_gap(p_left, p_right):\n",
    "    xL, yL = p_left\n",
    "    xR, yR = p_right\n",
    "    draw_centered_slash((xL, yL))\n",
    "    draw_centered_slash((xR, yR))\n",
    "    fig.add_artist(Line2D([xL + dx_fig/2, xR - dx_fig/2], [yL, yL],\n",
    "                          transform=fig.transFigure, linestyle=connector_ls,\n",
    "                          lw=connector_lw, color=connector_color, clip_on=False))\n",
    "\n",
    "draw_gap(pL_right, pM_left)\n",
    "draw_gap(pM_right, pR_left)\n",
    "\n",
    "xE, yE = pR_right\n",
    "draw_centered_slash((xE, yE))\n",
    "fig.add_artist(Line2D([xE + dx_fig/2, xE + dx_fig/2 + stub], [yE, yE],\n",
    "                      transform=fig.transFigure, linestyle=connector_ls,\n",
    "                      lw=connector_lw, color=connector_color, clip_on=False))\n",
    "\n",
    "def axes_to_fig(ax, xy):\n",
    "    return fig.transFigure.inverted().transform(ax.transAxes.transform(xy))\n",
    "\n",
    "pM_bottom = axes_to_fig(ax_m, (0.0, 0.0))\n",
    "pM_top    = axes_to_fig(ax_m, (0.0, 1.0))\n",
    "pR_bottom = axes_to_fig(ax_r, (0.0, 0.0))\n",
    "pR_top    = axes_to_fig(ax_r, (0.0, 1.0))\n",
    "\n",
    "x_mid = 0.5 * (axes_to_fig(ax_m, (1.0, 0.0))[0] + axes_to_fig(ax_r, (0.0, 0.0))[0])\n",
    "y_bot = min(pM_bottom[1], pR_bottom[1])\n",
    "y_top = max(pM_top[1],    pR_top[1])\n",
    "fig.add_artist(Line2D([x_mid, x_mid], [y_bot-0.05, y_top+0.05],\n",
    "                      transform=fig.transFigure, linestyle='--',\n",
    "                      lw=connector_lw, color=connector_color, clip_on=False))\n",
    "\n",
    "\n",
    "# ====== BOTTOM-RIGHT: Decision-time (frames) vs Test accuracy (Maya) on ax_br ======\n",
    "# Load & aggregate (same logic as your standalone script)\n",
    "with open('data/gridsearch_rapid_inference_short.pkl', 'rb') as f:\n",
    "    data_rapid = pickle.load(f)\n",
    "\n",
    "ns_raw  = np.asarray(data_rapid['params']['n_sample'])\n",
    "acc_raw = np.asarray(data_rapid['results']['test_acc'], dtype=float)\n",
    "\n",
    "x_vals_frames = sorted(set(int(x) for x in ns_raw))\n",
    "means_frames, stds_frames = [], []\n",
    "for ns in x_vals_frames:\n",
    "    vals = acc_raw[ns_raw == ns]\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    if vals.size == 0:\n",
    "        means_frames.append(np.nan)\n",
    "        stds_frames.append(np.nan)\n",
    "    else:\n",
    "        means_frames.append(float(np.mean(vals)))\n",
    "        stds_frames.append(float(np.std(vals, ddof=1)) if vals.size > 1 else 0.0)\n",
    "\n",
    "x_frames = np.asarray(x_vals_frames, dtype=float)\n",
    "\n",
    "# Small horizontal offset scale (kept for consistency with your style)\n",
    "dx_frames = (np.diff(np.unique(x_frames)).min() if x_frames.size > 1 else 1.0) * 0.05\n",
    "\n",
    "# Choose color (use your palette[1] if available, else fall back to rc cycle)\n",
    "try:\n",
    "    color_maya = palette[1]\n",
    "except Exception:\n",
    "    cycle_colors = plt.rcParams['axes.prop_cycle'].by_key().get('color', ['C0', 'C1'])\n",
    "    color_maya = cycle_colors[1] if len(cycle_colors) > 1 else 'C1'\n",
    "\n",
    "# Draw on the existing bottom-right axis\n",
    "ax_br.errorbar(\n",
    "    x_frames, means_frames, yerr=stds_frames,\n",
    "    linestyle='', linewidth=1.2, alpha=1.,\n",
    "    marker='+', markersize=5,\n",
    "    capsize=0, clip_on=False,\n",
    "    color=color_maya\n",
    ")\n",
    "\n",
    "# Axis labels\n",
    "ax_br.set_xlabel(\"Decision time (# of sensor readings)\")\n",
    "ax_br.set_ylabel(\"Test accuracy\")\n",
    "\n",
    "# Axis limits + ticks\n",
    "ax_br.set_xlim(0.5, x_frames.max() if x_frames.size else 1.0)\n",
    "ax_br.set_ylim(0, 1)\n",
    "ax_br.set_xticks(x_frames, labels=[str(int(v)) for v in x_frames])\n",
    "ax_br.set_yticks([0, 0.5, 1.0])\n",
    "\n",
    "# Bound bottom spine from first to last tick (matches your style)\n",
    "if x_frames.size:\n",
    "    ax_br.spines[\"bottom\"].set_bounds(x_frames[0], x_frames[-1])\n",
    "\n",
    "color_text = 'grey'\n",
    "ax_br.axhline(\n",
    "    y=test_acc,\n",
    "    linestyle='--',\n",
    "    linewidth=1.,\n",
    "    color=color_text\n",
    ")\n",
    "\n",
    "# Inline label at the last point\n",
    "if x_frames.size:\n",
    "    ax_br.text(\n",
    "        x_frames[-1] - 0.02, test_acc + 0.05,\n",
    "        \"$t=20$ readings\", color=color_text,\n",
    "        va=\"center\", ha=\"right\", fontsize=12\n",
    "    )\n",
    "\n",
    "# ====== BOTTOM-LEFT: SVM vs Maya plot (drawn on ax_br) ======\n",
    "# (your original data + pipeline code stays the same up to the plotting stage)\n",
    "# --- BEGIN: your SVM vs Maya data prep (unchanged) ---\n",
    "import pickle\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import loguniform\n",
    "from tools import get_samples\n",
    "\n",
    "n_samples_list = [3, 9, 15, 30]\n",
    "test_file = '1_600_20'\n",
    "\n",
    "data, sequence, times_sec, sequence_sec = load(test_file, reduced=True)\n",
    "_, _, X_test, Y_test = get_samples(\n",
    "    data, sequence, times_sec, sequence_sec,\n",
    "    idx_split=450\n",
    ")\n",
    "\n",
    "acc_means = {\"linear\": [], \"rbf\": [], \"poly\": [], \"sigmoid\": []}\n",
    "grid_means, grid_stds = [], []\n",
    "\n",
    "for n_samples in n_samples_list:\n",
    "    train_data, train_seq, train_times, train_seq_times = load(f'1_{n_samples}_20', reduced=True)\n",
    "    X_train, Y_train, _, _ = get_samples(\n",
    "        train_data, train_seq, train_times, train_seq_times,\n",
    "        idx_split=450\n",
    "    )\n",
    "    n_train = len(Y_train)\n",
    "\n",
    "    clf_lin = svm.SVC(kernel=\"linear\")\n",
    "    clf_lin.fit(X_train, Y_train)\n",
    "    acc_means[\"linear\"].append(metrics.accuracy_score(Y_test, clf_lin.predict(X_test)))\n",
    "\n",
    "    cv = KFold(n_splits=min(3, n_train), shuffle=True, random_state=42)\n",
    "    param_dist_rbf = {\"svc__C\": loguniform(1e-2, 1e3), \"svc__gamma\": loguniform(1e-3, 1e1)}\n",
    "    search_rbf = RandomizedSearchCV(\n",
    "        make_pipeline(StandardScaler(), svm.SVC(kernel=\"rbf\")),\n",
    "        param_distributions=param_dist_rbf, n_iter=30, cv=cv,\n",
    "        scoring=\"accuracy\", n_jobs=-1, random_state=42\n",
    "    )\n",
    "    search_rbf.fit(X_train, Y_train)\n",
    "    acc_means[\"rbf\"].append(metrics.accuracy_score(Y_test, search_rbf.best_estimator_.predict(X_test)))\n",
    "\n",
    "    param_dist_poly = {\"svc__C\": loguniform(1e-2, 1e3), \"svc__degree\": [2, 3, 4], \"svc__gamma\": loguniform(1e-3, 1e1)}\n",
    "    search_poly = RandomizedSearchCV(\n",
    "        make_pipeline(StandardScaler(), svm.SVC(kernel=\"poly\")),\n",
    "        param_distributions=param_dist_poly, n_iter=30, cv=cv,\n",
    "        scoring=\"accuracy\", n_jobs=-1, random_state=42\n",
    "    )\n",
    "    search_poly.fit(X_train, Y_train)\n",
    "    acc_means[\"poly\"].append(metrics.accuracy_score(Y_test, search_poly.best_estimator_.predict(X_test)))\n",
    "\n",
    "    param_dist_sig = {\"svc__C\": loguniform(1e-2, 1e3), \"svc__gamma\": loguniform(1e-3, 1e1)}\n",
    "    search_sig = RandomizedSearchCV(\n",
    "        make_pipeline(StandardScaler(), svm.SVC(kernel=\"sigmoid\")),\n",
    "        param_distributions=param_dist_sig, n_iter=30, cv=cv,\n",
    "        scoring=\"accuracy\", n_jobs=-1, random_state=42\n",
    "    )\n",
    "    search_sig.fit(X_train, Y_train)\n",
    "    acc_means[\"sigmoid\"].append(metrics.accuracy_score(Y_test, search_sig.best_estimator_.predict(X_test)))\n",
    "\n",
    "    with open(f'data/gridsearch_1_{n_samples}_20.pkl', 'rb') as f:\n",
    "        data_gs = pickle.load(f)\n",
    "    params = data_gs['params']\n",
    "    results = data_gs['results']\n",
    "\n",
    "    grid_accs = []\n",
    "    for k in np.unique(params['k']):\n",
    "        for n_pot in np.unique(params['n_pot']):\n",
    "            for t_delay in np.unique(params['t_training_delay']):\n",
    "                flags = np.stack((\n",
    "                    params['k'] == k,\n",
    "                    params['n_pot'] == n_pot,\n",
    "                    params['t_training_delay'] == t_delay\n",
    "                ), axis=1).all(axis=1)\n",
    "                accs_fold = results['test_acc'][flags]\n",
    "                if len(accs_fold) > 0:\n",
    "                    grid_accs.append(np.mean(accs_fold))\n",
    "    best_acc = np.max(grid_accs)\n",
    "    grid_means.append(best_acc)\n",
    "\n",
    "    best_flags = None\n",
    "    for k in np.unique(params['k']):\n",
    "        for n_pot in np.unique(params['n_pot']):\n",
    "            for t_delay in np.unique(params['t_training_delay']):\n",
    "                flags = np.stack((\n",
    "                    params['k'] == k,\n",
    "                    params['n_pot'] == n_pot,\n",
    "                    params['t_training_delay'] == t_delay\n",
    "                ), axis=1).all(axis=1)\n",
    "                accs_fold = results['test_acc'][flags]\n",
    "                if len(accs_fold) > 0 and np.mean(accs_fold) == best_acc:\n",
    "                    best_flags = flags\n",
    "                    break\n",
    "            if best_flags is not None:\n",
    "                break\n",
    "        if best_flags is not None:\n",
    "            break\n",
    "    grid_stds.append(np.std(results['test_acc'][best_flags]))\n",
    "\n",
    "avg_means, avg_stds = [], []\n",
    "for i in range(len(n_samples_list)):\n",
    "    kernel_means = [acc_means[k][i] for k in acc_means.keys()]\n",
    "    avg_means.append(np.mean(kernel_means))\n",
    "    avg_stds.append(np.std(kernel_means))\n",
    "# --- END: your SVM vs Maya data prep ---\n",
    "\n",
    "# --- Draw the SVM vs Maya plot on ax_br (INSTEAD of plt.figure/plt.errorbar) ---\n",
    "x_vals = np.array(n_samples_list) / 3.0\n",
    "x = np.asarray(x_vals)\n",
    "dx = (np.diff(np.unique(x)).min() if x.size > 1 else 1.0) * 0.05\n",
    "\n",
    "# use default color cycle for two series if `palette` is not defined\n",
    "try:\n",
    "    c_svm, c_maya = palette[0], palette[1]\n",
    "except Exception:\n",
    "    cycler_colors = plt.rcParams['axes.prop_cycle'].by_key().get('color', ['C0', 'C1'])\n",
    "    c_svm = cycler_colors[0] if len(cycler_colors) > 0 else 'C0'\n",
    "    c_maya = cycler_colors[1] if len(cycler_colors) > 1 else 'C1'\n",
    "\n",
    "ax_bl.errorbar(\n",
    "    x - dx, avg_means, yerr=avg_stds,\n",
    "    linestyle='', linewidth=1.2, alpha=1., marker='+', markersize=5,\n",
    "    capsize=0, clip_on=False, color=c_svm, label='SVM'\n",
    ")\n",
    "ax_bl.errorbar(\n",
    "    x + dx, grid_means, yerr=grid_stds,\n",
    "    linestyle='', linewidth=1.2, alpha=1., marker='+', markersize=5,\n",
    "    capsize=0, clip_on=False, color=c_maya, label='Maya'\n",
    ")\n",
    "\n",
    "\n",
    "ax_bl.set_xlabel(\"Training set size\",)\n",
    "ax_bl.set_ylabel(\"Test accuracy\", )\n",
    "ax_bl.set_xlim(0.5, max(x_vals))\n",
    "ax_bl.set_ylim(0, 1)\n",
    "ax_bl.set_xticks(x_vals, labels=[str(int(v)) for v in x_vals])\n",
    "ax_bl.set_yticks([0, 0.5, 1])\n",
    "\n",
    "ax_bl.grid(False)\n",
    "ax_bl.spines[\"top\"].set_visible(False)\n",
    "ax_bl.spines[\"right\"].set_visible(False)\n",
    "ax_bl.tick_params(axis=\"both\", width=1., length=6, )\n",
    "ax_bl.spines[\"bottom\"].set_bounds(1, max(x_vals))\n",
    "\n",
    "# inline labels\n",
    "# ax_bl.text(x_vals[-1] + 0.3, avg_means[-1],  \"SVM\",  color=c_svm,  va=\"center\", ha=\"left\", size=12)\n",
    "# ax_bl.text(x_vals[-1] + 0.3, grid_means[-1], \"Maya\", color=c_maya, va=\"center\", ha=\"left\", size=12)\n",
    "ax_bl.legend(bbox_to_anchor=(1.05, 0.4))\n",
    "\n",
    "# ----- Save the COMBINED figure -----\n",
    "# plt.tight_layout()\n",
    "plt.savefig(\"figs/combined_classification.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"figs/combined_classification.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ],
   "id": "3fcba72cc068c73b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ddf5901a990af193",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "93a41fff76bc04ad",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
