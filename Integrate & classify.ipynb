{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-01T11:46:01.664748Z",
     "start_time": "2025-08-01T11:45:57.270736Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "import torch\n",
    "from torch.linalg import inv, eig, pinv\n",
    "from matplotlib import pyplot as plt\n",
    "from tools import whiten\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T11:46:01.678187Z",
     "start_time": "2025-08-01T11:46:01.673920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load(filename, reduced=True):\n",
    "    sensor_data = []\n",
    "    times = []\n",
    "    responding_sens = [0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0]\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # times = [row[0] for row in reader]\n",
    "        for row in reader:\n",
    "            if row[0] =='Timestamp':\n",
    "                continue\n",
    "            else:\n",
    "                times.append(row[0])\n",
    "                values = []\n",
    "                for i in range(17):\n",
    "                    b1 = int(row[2*i+1])\n",
    "                    b2 = int(row[2*i+2])\n",
    "                    values.append(int.from_bytes([b1, b2], byteorder=\"little\"))\n",
    "                sensor_data.append(values)\n",
    "    sensor_data = np.array(sensor_data)\n",
    "    if reduced:\n",
    "        sensor_data = np.delete(sensor_data, np.where(np.array(responding_sens)==0)[0], axis=1)\n",
    "    sequence = pickle.load(open('data/1_300_20_sequence.pkl', 'rb'))\n",
    "    # Convert to seconds\n",
    "    times_sec = []\n",
    "    for dt_str in times:\n",
    "        dt = datetime.strptime(dt_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "        seconds = dt.hour * 3600 + dt.minute * 60 + dt.second + dt.microsecond / 1e6\n",
    "        times_sec.append(seconds)\n",
    "    sequence_sec = []\n",
    "    for dt_str in sequence:\n",
    "        dt = datetime.strptime(dt_str[0], '%a %b %d %H:%M:%S %Y')\n",
    "        seconds = dt.hour * 3600 + dt.minute * 60 + dt.second\n",
    "        sequence_sec.append(seconds)\n",
    "    times_sec = np.array(times_sec)\n",
    "    sequence_sec = np.array(sequence_sec)\n",
    "    return sensor_data, sequence, times_sec, sequence_sec"
   ],
   "id": "50e9f394b5478977",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T11:46:01.830350Z",
     "start_time": "2025-08-01T11:46:01.721613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename = 'data/1_300_20.csv'\n",
    "\n",
    "sensor_data, sequence, times_sec, sequence_sec = load(filename, reduced=False)"
   ],
   "id": "c8f80472c1cedf0b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T11:46:01.875347Z",
     "start_time": "2025-08-01T11:46:01.846271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "delay = 1.5\n",
    "t_baseline = 300\n",
    "n_train = 225\n",
    "\n",
    "\n",
    "baseline = np.mean(sensor_data[:t_baseline], axis=0)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "I_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "I_test = []\n",
    "counts = np.zeros((3))\n",
    "\n",
    "for i, t in enumerate(sequence_sec):\n",
    "    try:\n",
    "        flags = (times_sec > sequence_sec[i]) & (times_sec < sequence_sec[i+1] + delay)\n",
    "    except IndexError:\n",
    "        flags = (times_sec > sequence_sec[i])\n",
    "    sample = sensor_data[flags][:18]\n",
    "    t_sample = times_sec[flags][:18]\n",
    "\n",
    "    responding_sens = [0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0]\n",
    "    sample = np.delete(sample, np.where(np.array(responding_sens)==0)[0], axis=1)\n",
    "\n",
    "    x0 = sample[0, :]\n",
    "    t0 = t_sample[0]\n",
    "    sum = np.zeros((sample.shape[1]))\n",
    "    for k in range(1, sample.shape[0]):\n",
    "        dif = np.abs(sample[k, :] - x0)/(t_sample[k] - t0)\n",
    "        sum += dif\n",
    "\n",
    "    if counts[sequence[i][1]-1] < n_train//3:\n",
    "        X_train.append(sample.flatten())\n",
    "        Y_train.append(sequence[i][1]-1)\n",
    "        I_train.append(sum)\n",
    "        counts[sequence[i][1]-1] += 1\n",
    "    else:\n",
    "        X_test.append(sample.flatten())\n",
    "        Y_test.append(sequence[i][1]-1)\n",
    "        I_test.append(sum)\n",
    "\n",
    "    # if i<225:\n",
    "    #     X_train.append(sample.flatten())\n",
    "    #     Y_train.append(sequence[i][1]-1)\n",
    "    # else:\n",
    "    #     X_test.append(sample.flatten())\n",
    "    #     Y_test.append(sequence[i][1]-1)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "I_train = np.array(I_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "I_test = np.array(I_test)"
   ],
   "id": "17bd68237e8d9433",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T11:47:01.413833Z",
     "start_time": "2025-08-01T11:46:57.084576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_out = 3\n",
    "n_hd = 10000\n",
    "k = 50\n",
    "w_teacher = 1.\n",
    "n_pot = 10\n",
    "uniformW = False\n",
    "train_epoch = 20\n",
    "n_dense = I_train.shape[1]\n",
    "\n",
    "if uniformW:\n",
    "    W_hd = np.random.uniform(high=1/np.sqrt(n_dense), size=(n_hd, n_dense))  #Test random sparse weights\n",
    "else:\n",
    "    W_hd = np.random.binomial(n=1, p=0.05, size=(n_hd, n_dense))  #Test random sparse weights\n",
    "\n",
    "W_out = np.zeros((n_out, n_hd))\n",
    "W = np.zeros((n_out, n_hd))\n",
    "\n",
    "for epoch in range(train_epoch):\n",
    "    x_dense = I_train\n",
    "    labels = np.concatenate((Y_train, Y_test))\n",
    "\n",
    "    x_hd = x_dense @ W_hd.T\n",
    "    z_hd = np.where(np.argsort(x_hd)<k, 1., 0)\n",
    "\n",
    "    z_out_train = np.zeros((z_hd.shape[0],  n_out))\n",
    "    for i, row in enumerate(z_hd):\n",
    "        teacher = np.zeros((n_out,))\n",
    "        if labels[i] != 0:\n",
    "            teacher[int(labels[i])] = w_teacher\n",
    "        out = row @ W_out.T + teacher\n",
    "        z_out_train[i] = out\n",
    "        dW = (1./n_pot)*(np.atleast_2d(out).T @ np.atleast_2d(row))\n",
    "        W += dW\n",
    "        W_out = np.where(W>=1., 1./k, 0.)\n",
    "        # if i%100 == 0:\n",
    "        #     print(np.sum(W_out, axis=1))\n",
    "\n",
    "    x_dense = np.vstack((I_train, I_test))\n",
    "    x_hd = x_dense @ W_hd.T\n",
    "    z_hd = np.where(np.argsort(x_hd)<k, 1., 0)\n",
    "\n",
    "    z_out = np.zeros((z_hd.shape[0],  n_out))\n",
    "    for i, row in enumerate(z_hd):\n",
    "        out = row @ W_out.T\n",
    "        z_out[i] = out\n",
    "\n",
    "    # z_wta = np.where(np.argsort(z_out, axis=1)<1, 1., 0)\n",
    "\n",
    "    z_pred = np.zeros_like(z_out)\n",
    "    z_pred = np.argsort(z_out, axis=1)[:, -1]\n",
    "\n",
    "    train_acc = metrics.accuracy_score(labels[:n_train], z_pred[:n_train])\n",
    "    test_acc = metrics.accuracy_score(labels[n_train:], z_pred[n_train:])\n",
    "\n",
    "    # results['train_acc'].append(train_acc)\n",
    "    # results['test_acc'].append(test_acc)\n",
    "    #\n",
    "    # print(f'UniformW: {uniformW}, Normalized: {normalized}, Whitened: {whitened}, k: {k}, n_pot: {n_pot}, t_training_delay: {t_training_delay}, n_fold: {n_fold}')\n",
    "    print(f'Epoch: {epoch}\\tTrain accuracy: {train_acc:.4f}\\tTest accuracy: {test_acc:.4f}')\n"
   ],
   "id": "40d6dfb15a34ad1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tTrain accuracy: 0.3822\tTest accuracy: 0.3600\n",
      "Epoch: 1\tTrain accuracy: 0.5067\tTest accuracy: 0.4533\n",
      "Epoch: 2\tTrain accuracy: 0.5778\tTest accuracy: 0.4533\n",
      "Epoch: 3\tTrain accuracy: 0.6400\tTest accuracy: 0.4800\n",
      "Epoch: 4\tTrain accuracy: 0.6356\tTest accuracy: 0.4533\n",
      "Epoch: 5\tTrain accuracy: 0.6444\tTest accuracy: 0.4400\n",
      "Epoch: 6\tTrain accuracy: 0.6622\tTest accuracy: 0.4267\n",
      "Epoch: 7\tTrain accuracy: 0.6533\tTest accuracy: 0.4267\n",
      "Epoch: 8\tTrain accuracy: 0.6533\tTest accuracy: 0.4267\n",
      "Epoch: 9\tTrain accuracy: 0.6533\tTest accuracy: 0.4267\n",
      "Epoch: 10\tTrain accuracy: 0.6533\tTest accuracy: 0.4267\n",
      "Epoch: 11\tTrain accuracy: 0.6222\tTest accuracy: 0.4000\n",
      "Epoch: 12\tTrain accuracy: 0.5600\tTest accuracy: 0.3867\n",
      "Epoch: 13\tTrain accuracy: 0.4711\tTest accuracy: 0.4000\n",
      "Epoch: 14\tTrain accuracy: 0.4311\tTest accuracy: 0.3733\n",
      "Epoch: 15\tTrain accuracy: 0.4089\tTest accuracy: 0.3867\n",
      "Epoch: 16\tTrain accuracy: 0.3778\tTest accuracy: 0.3600\n",
      "Epoch: 17\tTrain accuracy: 0.3689\tTest accuracy: 0.3600\n",
      "Epoch: 18\tTrain accuracy: 0.3689\tTest accuracy: 0.3867\n",
      "Epoch: 19\tTrain accuracy: 0.3556\tTest accuracy: 0.3467\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
